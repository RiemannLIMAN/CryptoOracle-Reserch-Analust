import os
import requests
import json
import logging
from config.settings import LLM_API_KEY, LLM_BASE_URL, LLM_MODEL

logger = logging.getLogger("llm_client")

class LLMClient:
    def __init__(self):
        self.api_key = LLM_API_KEY
        self.base_url = LLM_BASE_URL
        self.model = LLM_MODEL
        
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æžœç”¨æˆ·åªé…ç½®äº† base_url (å¦‚ https://api.deepseek.com) 
        # ä½†æ²¡æœ‰åŒ…å«å…·ä½“çš„ chat è·¯å¾„ï¼Œæˆ‘ä»¬å°è¯•è‡ªåŠ¨è¡¥å……æ ‡å‡† OpenAI æ ¼å¼è·¯å¾„
        if self.base_url and not self.base_url.endswith("/chat/completions"):
            # å¦‚æžœç»“å°¾æ˜¯ /v1ï¼Œåˆ™è¡¥å…¨ /chat/completions
            if self.base_url.endswith("/v1"):
                self.base_url = f"{self.base_url}/chat/completions"
            # å¦åˆ™å‡è®¾è¿™æ˜¯ä¸€ä¸ªæ ¹åŸŸåï¼Œå°è¯•è¡¥å…… /chat/completions æˆ– /v1/chat/completions
            # è¿™é‡Œä¸ºäº†é€šç”¨æ€§ï¼Œé»˜è®¤å‡è®¾ç”¨æˆ·å¡«å†™çš„æ˜¯ base_url (e.g. https://api.openai.com/v1)
            # å¦‚æžœç”¨æˆ·å¡«å†™çš„å·²ç»æ˜¯å®Œæ•´è·¯å¾„ï¼Œåˆ™ä¸æ”¹åŠ¨
            else:
                self.base_url = f"{self.base_url.rstrip('/')}/chat/completions"

        if not self.api_key:
            logger.warning("Notice: LLM_API_KEY not found. AI analysis will not be available.")
        else:
            logger.debug(f"LLM Client initialized with model: {self.model}")

    def analyze_market(self, market_data_summary, user_query=""):
        """
        åˆ©ç”¨ LLM åˆ†æžå¸‚åœºæ•°æ®
        :param market_data_summary: å¸‚åœºæ•°æ®çš„æ‘˜è¦å­—ç¬¦ä¸²
        :param user_query: ç”¨æˆ·ç‰¹å®šçš„æŸ¥è¯¢éœ€æ±‚
        """
        if not self.api_key:
            return "Error: LLM API Key is missing. Please configure .env file."

        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ å¯†è´§å¸å¸‚åœºåˆ†æžå¸ˆã€‚ä½ çš„åˆ†æžé£Žæ ¼éœ€è¦å…¼å¤‡ä¸“ä¸šæ·±åº¦ä¸Žé€šä¿—æ˜“æ‡‚æ€§ï¼Œå³ä¾¿æ˜¯æ–°æ‰‹ä¹Ÿèƒ½ç†è§£å¤æ‚çš„å¸‚åœºåŠ¨æ€ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„å¸‚åœºæ•°æ®ï¼Œåˆ†æžå¸ç§çš„åŒºåˆ«ï¼Œå¹¶ç»™å‡ºæŠ•èµ„å»ºè®®ã€‚

è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è¾“å‡ºæ ¼å¼è¦æ±‚ï¼Œä¸è¦åŒ…å«ä»»ä½•å¯’æš„è¯­ï¼ˆå¦‚â€œä½ å¥½â€ã€â€œä½œä¸ºåˆ†æžå¸ˆ...â€ï¼‰ï¼š

1. **æ ¸å¿ƒå¸‚åœºæ‘˜è¦**ï¼šç”¨ç®€ç»ƒä¸”é€šä¿—çš„è¯­è¨€æ€»ç»“å½“å‰å¸‚åœºæ•´ä½“æƒ…ç»ªï¼ˆ100å­—ä»¥å†…ï¼‰ã€‚
2. **é‡ç‚¹å¸ç§åˆ†æžè¡¨æ ¼**ï¼šå¿…é¡»ä½¿ç”¨ Markdown è¡¨æ ¼å½¢å¼ï¼Œåˆ—å¤´åŒ…å«ï¼šå¸ç§ã€èµ›é“ã€24hæ¶¨è·Œå¹…ã€åˆ†æžä¸Žè¯„ä»·ï¼ˆç®€çŸ­ä¸”æ˜“æ‡‚ï¼‰ã€‚é€‰å–3-5ä¸ªæœ€å…·ä»£è¡¨æ€§çš„å¸ç§ã€‚
3. **èµ›é“æœºä¼šä¸Žé£Žé™©**ï¼š
   - ðŸŸ¢ **æœºä¼š**ï¼šåˆ—å‡º1-2ä¸ªæ½œåŠ›èµ›é“æˆ–å¸ç§ï¼Œå¹¶è¯´æ˜Žç†ç”±ï¼ˆé€»è¾‘æ¸…æ™°ï¼Œé€šä¿—æ˜“æ‡‚ï¼‰ã€‚
   - ðŸ”´ **é£Žé™©**ï¼šåˆ—å‡ºéœ€å›žé¿çš„æ¿å—æˆ–å¸ç§ã€‚
4. **æŠ•èµ„å»ºè®®**ï¼šé’ˆå¯¹ç¨³å¥åž‹å’Œæ¿€è¿›åž‹æŠ•èµ„è€…çš„å…·ä½“æ“ä½œå»ºè®®ï¼Œå»ºè®®éœ€å…·ä½“ä¸”æ˜“äºŽæ‰§è¡Œã€‚

ä¿æŒå®¢è§‚ã€ç†æ€§ï¼Œæ•°æ®é©±åŠ¨ã€‚è¯­è¨€é£Žæ ¼éœ€ä¸“ä¸šä¸¥è°¨ä½†é€šä¿—æ˜“æ‡‚ï¼Œé¿å…è¿‡åº¦å †ç Œæœ¯è¯­ï¼Œå¯¹å…³é”®æ¦‚å¿µå¯åšç®€è¦è§£é‡Šã€‚ä½¿ç”¨ Markdown æ ¼å¼ä¼˜åŒ–æŽ’ç‰ˆã€‚
"""
        
        user_prompt = f"""
ä»¥ä¸‹æ˜¯å½“å‰ OKX å¸‚åœºçš„éƒ¨åˆ†çƒ­é—¨å¸ç§æ•°æ®æ‘˜è¦ï¼ˆå·²æŒ‰äº¤æ˜“é‡æŽ’åºï¼‰ï¼š
{market_data_summary}

ç”¨æˆ·çš„éœ€æ±‚æ˜¯ï¼š{user_query if user_query else "åˆ†æžè¿™äº›å¸ç§çš„åŒºåˆ«ï¼Œå¹¶æŽ¨èå€¼å¾—å…³æ³¨çš„å¸ç§ã€‚"}

è¯·ç»™å‡ºè¯¦ç»†çš„åˆ†æžæŠ¥å‘Šã€‚
"""

        return self._call_llm(system_prompt, user_prompt)

    def classify_sectors(self, coin_list):
        """
        åˆ©ç”¨ LLM å¯¹å¸ç§è¿›è¡Œèµ›é“åˆ†ç±»
        :param coin_list: å¸ç§åˆ—è¡¨ (list of strings)
        :return: å­—å…¸ {coin: sector}
        """
        if not self.api_key:
            return {}

        coins_str = ", ".join(coin_list)
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªåŠ å¯†è´§å¸é¢†åŸŸçš„ä¸“å®¶ç™¾ç§‘å…¨ä¹¦ã€‚ä½ çš„ä»»åŠ¡æ˜¯è¯†åˆ«ç»™å®šå¸ç§æ‰€å±žçš„ä¸»æµèµ›é“ï¼ˆSectorï¼‰ã€‚
åªè¿”å›žçº¯ JSON æ ¼å¼æ•°æ®ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°æˆ–å…¶ä»–æ–‡å­—ã€‚
æ ¼å¼è¦æ±‚ï¼š{"BTC": "Layer1", "UNI": "DeFi", ...}
èµ›é“åˆ†ç±»å‚è€ƒï¼šLayer1, Layer2, DeFi, Meme, AI, GameFi, RWA, Storage, Oracle ç­‰ã€‚å¦‚æžœä¸çŸ¥é“ï¼Œæ ‡è®°ä¸º "Unknown"ã€‚
"""
        user_prompt = f"è¯·å¯¹ä»¥ä¸‹å¸ç§è¿›è¡Œåˆ†ç±»ï¼š{coins_str}"
        
        try:
            response_text = self._call_llm(system_prompt, user_prompt)
            # æ¸…ç†å¯èƒ½çš„ markdown æ ‡è®°
            response_text = response_text.replace("```json", "").replace("```", "").strip()
            return json.loads(response_text)
        except Exception as e:
            logger.error(f"Error classifying sectors: {e}")
            return {}

    def _call_llm(self, system_prompt, user_prompt):
        """é€šç”¨ LLM è°ƒç”¨æ–¹æ³•"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "stream": False
        }

        try:
            # logger.info(f"Sending request to LLM ({self.model})...") 
            # é¿å…æ—¥å¿—è¿‡äºŽå˜ˆæ‚ï¼Œä»…åœ¨ debug çº§åˆ«æˆ–å¤–éƒ¨è°ƒç”¨æ—¶è®°å½•
            response = requests.post(self.base_url, headers=headers, json=payload, timeout=60)
            response.raise_for_status()
            
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                return result['choices'][0]['message']['content']
            else:
                logger.error(f"Unexpected response structure: {result}")
                raise ValueError("Unexpected response from LLM API")
                
        except Exception as e:
            logger.error(f"Error calling LLM API: {e}")
            raise
