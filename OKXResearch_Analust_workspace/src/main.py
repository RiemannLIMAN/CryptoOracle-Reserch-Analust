import sys
import os
import pandas as pd

# å°† src ç›®å½•å’Œé¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° Python è·¯å¾„
src_path = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(src_path)
sys.path.append(src_path)
sys.path.append(project_root)

from api.okx_client import OKXClient
from api.llm_client import LLMClient
from analysis.fundamental import FundamentalAnalyzer
from analysis.technical import calculate_change
from api.news_client import NewsClient
from utils.logger import setup_logger
from utils.notifier import Notifier
from config.settings import LOG_DIR, ENABLE_SCHEDULER, SCHEDULE_TIME, SCHEDULE_INTERVAL, FEISHU_WEBHOOK_URL, DINGTALK_WEBHOOK_URL
# ä»æ ¹ç›®å½•çš„ __init__.py å¯¼å…¥ç‰ˆæœ¬ä¿¡æ¯
from src import __version__, __author__
import datetime
import logging
import schedule
import time
from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel

# é…ç½®å›ºå®šæ—¥å¿—æ–‡ä»¶åï¼Œä»¥ä¾¿ RotatingFileHandler ç”Ÿæ•ˆ
log_file = LOG_DIR / "okx_research.log"

# é…ç½® root loggerï¼Œä½¿å…¶è¾“å‡ºåˆ°æ–‡ä»¶å’Œæ§åˆ¶å°
# æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ name=None æ¥é…ç½® root logger
setup_logger(name=None, log_file=log_file)

# è·å– main æ¨¡å—çš„ logger
logger = logging.getLogger("main")

# åˆå§‹åŒ– Rich Console
console = Console()

def print_welcome():
    """æ‰“å°å¯åŠ¨æ¬¢è¿ä¿¡æ¯"""
    # è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
    logger.info(f"System Startup - Version: {__version__}, Author: {__author__}")
    
    # æ‰“å°åˆ°ç»ˆç«¯ UI
    console.print(Panel(
        f"[bold green]OKX Research Analyst[/bold green]\n"
        f"Version: [yellow]{__version__}[/yellow]\n"
        f"Author: [blue]{__author__}[/blue]\n"
        f"Time: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        title="ğŸš€ System Startup",
        border_style="green"
    ))

def format_data_for_llm(df, analyzer, funding_rates=None, top_n=20):
    """
    å°† DataFrame æ ¼å¼åŒ–ä¸º LLM æ˜“è¯»çš„å­—ç¬¦ä¸²ï¼Œå¹¶è¡¥å……èµ›é“ä¿¡æ¯
    """
    if funding_rates is None:
        funding_rates = {}

    # ç¡®ä¿ volCcy24h æ˜¯æ•°å€¼ç±»å‹
    df['volCcy24h'] = pd.to_numeric(df['volCcy24h'], errors='coerce')
    
    # æŒ‰æˆäº¤é¢æ’åº
    df_sorted = df.sort_values(by='volCcy24h', ascending=False).head(top_n)
    
    summary = []
    for _, row in df_sorted.iterrows():
        try:
            last_price = float(row['last'])
            open_price = float(row['open24h'])
            vol = float(row['volCcy24h'])
            
            # ä½¿ç”¨ technical æ¨¡å—è®¡ç®—æ¶¨è·Œå¹…
            change_pct = calculate_change(last_price, open_price)
            
            # è·å–èµ›é“ä¿¡æ¯
            inst_id = row['instId']
            # ä½¿ç”¨ä¼ å…¥çš„ analyzer å®ä¾‹ï¼Œåˆ©ç”¨å…¶ç¼“å­˜
            sector = analyzer.get_coin_sector(inst_id)
            
            line = (f"Symbol: {inst_id}, "
                    f"Price: {last_price}, "
                    f"Sector: {sector}, "
                    f"24h Change: {change_pct:.2f}%, "
                    f"24h Vol(USDT): {vol:.0f}")
            
            # è¡¥å……èµ„é‡‘è´¹ç‡ (å¦‚æœæœ‰)
            # inst_id å¦‚ BTC-USDTï¼Œfunding_rates é”®ä¹Ÿæ˜¯ BTC-USDT
            if inst_id in funding_rates:
                fr = funding_rates[inst_id]
                line += f", Funding Rate: {fr:.4f}%"
            
            summary.append(line)
        except ValueError:
            continue
            
    return "\n".join(summary)

def run_analysis_task(user_query=""):
    """
    æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„åˆ†æä»»åŠ¡ï¼šæŠ“å– -> é¢„å¤„ç† -> åˆ†æ -> å±•ç¤º/é€šçŸ¥
    """
    try:
        logger.info("Starting analysis task...")
        
        okx = OKXClient()
        llm = LLMClient()
        news = NewsClient()
        
        # 1. è·å–æ•°æ®
        logger.info("Fetching market data from OKX...")
        df = okx.get_tickers()
        
        # 1.1 è·å–èµ„é‡‘è´¹ç‡ (ä½œä¸ºå¤§ç›˜æƒ…ç»ªå‚è€ƒ)
        # è™½ç„¶è¿™é‡Œåªè·å–äº†éƒ¨åˆ†ä¸»æµå¸çš„è´¹ç‡ï¼Œä½†å¯¹ AI åˆ¤æ–­å¸‚åœºæƒ…ç»ªå¾ˆæœ‰ç”¨
        logger.info("Fetching funding rates...")
        funding_rates = okx.get_funding_rates()
        
        # 1.2 è·å–æ–°é—» (æ–°å¢)
        logger.info("Fetching latest crypto news...")
        # è·å–çƒ­é—¨æ–°é—»ï¼Œæ¶µç›–ä¸»æµå¸
        raw_news = news.get_latest_news(filter="hot", currencies=["BTC", "ETH", "SOL"], limit=5)
        
        # 1.3 LLM éªŒè¯æ–°é—»
        verified_news = None
        if raw_news and llm.api_key:
            logger.info("Verifying news authenticity with AI...")
            verified_news = llm.verify_and_analyze_news(raw_news)
        
        if df is None or df.empty:
            logger.error("Failed to fetch data or data is empty.")
            return

        # 2. é¢„å¤„ç†
        logger.info(f"Fetched {len(df)} tickers. Preparing top 30 by volume for analysis...")
        
        # æå‰ä½¿ç”¨ AI æ‰¹é‡è¯†åˆ«è¿™ Top 30 å¸ç§çš„èµ›é“
        # è¿™æ ·åœ¨ format_data_for_llm é‡Œå°±èƒ½ç›´æ¥ä»ç¼“å­˜æ‹¿æ•°æ®ï¼Œä¸ç”¨æ¯æ¬¡éƒ½è°ƒæ¥å£
        fundamental = FundamentalAnalyzer()
        top_coins = df.sort_values(by='volCcy24h', ascending=False).head(30)['instId'].tolist()
        
        # å¦‚æœé…ç½®äº† LLMï¼Œå°è¯•è‡ªåŠ¨è¯†åˆ«æœªçŸ¥èµ›é“
        if llm.api_key:
            fundamental.update_sectors_with_ai(top_coins)
            
        data_summary = format_data_for_llm(df, fundamental, funding_rates=funding_rates, top_n=30)
        
        # 3. åˆ†æ
        if not llm.api_key:
             logger.warning("LLM API key not configured. Skipping analysis.")
             return
        
        logger.info(f"User Query: {user_query if user_query else 'Default Analysis'}")

        # äº¤äº’æ¨¡å¼ä¸‹æ˜¾ç¤ºåŠ¨ç”»ï¼Œéäº¤äº’æ¨¡å¼(å®šæ—¶ä»»åŠ¡)åˆ™é™é»˜
        if sys.stdout.isatty():
            with console.status(f"[bold green]AI ({llm.model}) is thinking...", spinner="dots"):
                analysis = llm.analyze_market(data_summary, user_query, news_analysis=verified_news)
        else:
            logger.info(f"AI ({llm.model}) is analyzing...")
            analysis = llm.analyze_market(data_summary, user_query, news_analysis=verified_news)
            
        logger.info("Analysis completed.")

        # 4. å±•ç¤ºä¸é€šçŸ¥
        # ç»ˆç«¯è¾“å‡º
        console.print("\n")
        console.print(Panel(Markdown(analysis), title="ğŸ“Š OKX Market Analysis Report", border_style="blue"))
        
        # å°†å®Œæ•´çš„åˆ†ææŠ¥å‘Šå†™å…¥æ—¥å¿—æ–‡ä»¶ï¼Œä½œä¸ºå­˜æ¡£
        logger.info(f"Analysis Report Content:\n{'-'*50}\n{analysis}\n{'-'*50}")

        # æ¨é€é€šçŸ¥
        if FEISHU_WEBHOOK_URL or DINGTALK_WEBHOOK_URL:
            notifier = Notifier(feishu_webhook=FEISHU_WEBHOOK_URL, dingtalk_webhook=DINGTALK_WEBHOOK_URL)
            # æˆªå–æ‘˜è¦æˆ–å‘é€å®Œæ•´æŠ¥å‘Šï¼ˆæ³¨æ„æ¶ˆæ¯é•¿åº¦é™åˆ¶ï¼Œè¿™é‡Œå‘é€å‰500å­—ç¬¦æˆ–å®Œæ•´å†…å®¹ï¼‰
            # å®é™…ç”Ÿäº§ä¸­å¯èƒ½éœ€è¦æ‹†åˆ†å‘é€
            notifier.send("OKX Market Analysis Report", analysis)
            
    except Exception as e:
        logger.error(f"Error occurring during analysis task: {e}", exc_info=True)
        # åœ¨æ§åˆ¶å°ä¹Ÿæ‰“å°ä¸€ä¸‹ï¼Œæ–¹ä¾¿è°ƒè¯•ï¼ˆå¦‚æœæ˜¯äº¤äº’æ¨¡å¼ï¼‰
        if sys.stdout.isatty():
            console.print(f"[bold red]Task Error:[/bold red] {e}")

def main():
    # æ‰“å°æ¬¢è¿ä¿¡æ¯
    print_welcome()
    
    # è·å–å‘½ä»¤è¡Œå‚æ•°ä½œä¸ºç”¨æˆ·æŸ¥è¯¢
    user_query = " ".join(sys.argv[1:]) if len(sys.argv) > 1 else ""
    
    if ENABLE_SCHEDULER:
        if SCHEDULE_INTERVAL > 0:
            logger.info(f"Scheduler enabled. Task will run every {SCHEDULE_INTERVAL} minutes.")
            console.print(f"[bold green]Scheduler enabled. Running every {SCHEDULE_INTERVAL} minutes...[/bold green]")
            # ç«‹å³è¿è¡Œä¸€æ¬¡
            run_analysis_task(user_query)
            schedule.every(SCHEDULE_INTERVAL).minutes.do(run_analysis_task, user_query)
        else:
            logger.info(f"Scheduler enabled. Task will run daily at {SCHEDULE_TIME}.")
            console.print(f"[bold green]Scheduler enabled. Running daily at {SCHEDULE_TIME}...[/bold green]")
            # è®¾ç½®å®šæ—¶ä»»åŠ¡
            schedule.every().day.at(SCHEDULE_TIME).do(run_analysis_task, user_query)
        
        while True:
            schedule.run_pending()
            time.sleep(60)
    else:
        # å•æ¬¡è¿è¡Œæ¨¡å¼
        run_analysis_task(user_query)

if __name__ == "__main__":
    main()
